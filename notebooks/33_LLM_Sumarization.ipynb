{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45916260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\email\\Desktop\\2504_Aging_news\\2504_Aging_news\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import hub\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39de2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "hf_token = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Llama 3 model and tokenizer\n",
    "# running time was 7 min\n",
    "model_id =  \"meta-llama/Llama-3.2-1B\"#\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e46cf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text generation pipeline (it was without tranformers)\n",
    "text_generation_pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256, #max_length=512, #was 1024\n",
    "    temperature=0.5, # it was 0.7\n",
    "    top_p=0.8, # it was 0.9\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c66ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\email\\AppData\\Local\\Temp\\ipykernel_3804\\751951455.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
     ]
    }
   ],
   "source": [
    "# Wrap the pipeline in a LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbae431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    # FAISS.load_local needs the embeddings object to load the vector store\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    )\n",
    "    doc_vectorStore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    retriever = doc_vectorStore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f333fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chains(retriever):\n",
    "    # This chain takes a list of documents and formats them all into a prompt, then passes that prompt to the LLM. It passes all documents, so we need to make sure it fits within the context window of the LLM.\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\"),\n",
    "    ) \n",
    "    # this chain takes in a user inquiry, which is then passed to the retriever to fetch relevant documents. Those documents (and original inputs) are then passed to the LLM to generate response. \n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90186d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docName = \"docum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f524a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\email\\AppData\\Local\\Temp\\ipykernel_3804\\1803034753.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "custom_retriever = retrieve_from_vector_db(\"../data/vector_databases/\"+docName+\"_vector_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56387907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\email\\Desktop\\2504_Aging_news\\2504_Aging_news\\.venv\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retrievalChain = connect_chains(custom_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87451fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dialog = \"Please write me a summary of the text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c132d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(inquiry, retrieval_chain=retrievalChain):\n",
    "    result = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    print(result['answer'].strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aaa2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer any use questions based solely on the context below:\n",
      "\n",
      "<context>\n",
      "56:20 \n",
      "That's a big deal. This is, I think, a turning point in medical history, that we actually understand \n",
      "56:26 \n",
      "what causes those diseases fundamentally, not just trying to fix the actual problem when it occurs. \n",
      "56:32 \n",
      "I liken this to get getting to the edge of a cliff. And you wrote this in the book, \n",
      "56:38 \n",
      "is that we've been far too often working on trying to understand why we falling off a cliff \n",
      "56:44 \n",
      "at the end of life, without even asking the question, \"What brings us to the edge of that cliff in the first \n",
      "place.\" Now we finally understand how we get to that cliff, \n",
      "56:51 \n",
      "and even how to prevent it. - And so at some point perhaps we don't have to worry about diseases \n",
      "56:59 \n",
      "because we're going to be so healthy. So young that they're not going to push us off. \n",
      "57:06 \n",
      "They're going to make us sick, maybe. We can treat that. But- - Well, as we saw with COVID-19, that if\n",
      "you're young, \n",
      "57:12\n",
      "\n",
      "of where we were in Lifespan. \n",
      "12:21 \n",
      "There's a lot to talk about, including things that you can apply in your daily lives, that we didn't know \n",
      "when Lifespan was written. \n",
      "12:27 \n",
      "- One of misconceptions I think a lot of people have about the book, a lot of people have about your \n",
      "research, is they think that you're trying to prevent old age? \n",
      "12:36 \n",
      "- Well, we are, but that's not the only thing. - Because what we're talking about, really, is preventing \n",
      "aging, \n",
      "12:41 \n",
      "and that doesn't just happen when we are old. - Of course not. In fact, it happens over your whole entire\n",
      "lifespan, \n",
      "12:48 \n",
      "even before you're born. - We're going to get into exactly how we know that, but this is fascinating. \n",
      "This is a fascinating area of research. \n",
      "12:55 \n",
      "There's been recent studies on this, which can actually measure, in utero, an infant's age. \n",
      "13:01 \n",
      "- Yeah, in fact, when we're young, we're aging faster than when we're old. But we'll talk about that\n",
      "\n",
      "ourselves and others, \n",
      "3:20 \n",
      "is that we are at a turning point in medical history. We finally, as a species, \n",
      "3:25 \n",
      "understand how to control our biology, how to optimize our bodies, during early life, mid-life and \n",
      "certainly late life, \n",
      "3:33 \n",
      "to lead lives that can be decades longer and healthier. And we want to share that information. \n",
      "3:38 \n",
      "It's very hard for the average person to understand, let alone digest, thousands of scientific papers. \n",
      "3:45 \n",
      "That's what I do. I have a team of researchers and in fact, today, we're supported by a team of \n",
      "researchers who have helped us gather information\n",
      "\n",
      "haven't read the book, that's fine. \n",
      "0:48 \n",
      "We're going to go into detail in this episode, to give you a basis for what we're going to talk about in \n",
      "this series. \n",
      "0:54 \n",
      "- And if you have read the book, that's okay too, because so much has changed in the last three years \n",
      "1:01 \n",
      "since the book was published. - Right, so a little bit about you, before we get too much into the weeds. \n",
      "1:07 \n",
      "You're a writer. You used to be reporter. You've been a war correspondent. What am I missing? \n",
      "1:12 \n",
      "- I'm a professor of journalism at Utah State University. - Right, it's not Harvard University, but it's - - \n",
      "It's the Harvard University of the Mountain West. \n",
      "1:20 \n",
      "- Anyway, you're brilliant at writing, and I certainly couldn't have written this book without you. \n",
      "1:25 \n",
      "But this podcast... We talk a lot every week. - Yeah. - We're writing another book, \n",
      "1:31 \n",
      "which will be due out, we hope, probably next year? - Oh dear God.[laughs] - Yeah, well.. \n",
      "1:36\n",
      "</context>\n",
      "Human: Please write me a summary of the text, and I'll read it back to you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'System: Answer any use questions based solely on the context below:\\n\\n<context>\\n56:20 \\nThat\\'s a big deal. This is, I think, a turning point in medical history, that we actually understand \\n56:26 \\nwhat causes those diseases fundamentally, not just trying to fix the actual problem when it occurs. \\n56:32 \\nI liken this to get getting to the edge of a cliff. And you wrote this in the book, \\n56:38 \\nis that we\\'ve been far too often working on trying to understand why we falling off a cliff \\n56:44 \\nat the end of life, without even asking the question, \"What brings us to the edge of that cliff in the first \\nplace.\" Now we finally understand how we get to that cliff, \\n56:51 \\nand even how to prevent it. - And so at some point perhaps we don\\'t have to worry about diseases \\n56:59 \\nbecause we\\'re going to be so healthy. So young that they\\'re not going to push us off. \\n57:06 \\nThey\\'re going to make us sick, maybe. We can treat that. But- - Well, as we saw with COVID-19, that if\\nyou\\'re young, \\n57:12\\n\\nof where we were in Lifespan. \\n12:21 \\nThere\\'s a lot to talk about, including things that you can apply in your daily lives, that we didn\\'t know \\nwhen Lifespan was written. \\n12:27 \\n- One of misconceptions I think a lot of people have about the book, a lot of people have about your \\nresearch, is they think that you\\'re trying to prevent old age? \\n12:36 \\n- Well, we are, but that\\'s not the only thing. - Because what we\\'re talking about, really, is preventing \\naging, \\n12:41 \\nand that doesn\\'t just happen when we are old. - Of course not. In fact, it happens over your whole entire\\nlifespan, \\n12:48 \\neven before you\\'re born. - We\\'re going to get into exactly how we know that, but this is fascinating. \\nThis is a fascinating area of research. \\n12:55 \\nThere\\'s been recent studies on this, which can actually measure, in utero, an infant\\'s age. \\n13:01 \\n- Yeah, in fact, when we\\'re young, we\\'re aging faster than when we\\'re old. But we\\'ll talk about that\\n\\nourselves and others, \\n3:20 \\nis that we are at a turning point in medical history. We finally, as a species, \\n3:25 \\nunderstand how to control our biology, how to optimize our bodies, during early life, mid-life and \\ncertainly late life, \\n3:33 \\nto lead lives that can be decades longer and healthier. And we want to share that information. \\n3:38 \\nIt\\'s very hard for the average person to understand, let alone digest, thousands of scientific papers. \\n3:45 \\nThat\\'s what I do. I have a team of researchers and in fact, today, we\\'re supported by a team of \\nresearchers who have helped us gather information\\n\\nhaven\\'t read the book, that\\'s fine. \\n0:48 \\nWe\\'re going to go into detail in this episode, to give you a basis for what we\\'re going to talk about in \\nthis series. \\n0:54 \\n- And if you have read the book, that\\'s okay too, because so much has changed in the last three years \\n1:01 \\nsince the book was published. - Right, so a little bit about you, before we get too much into the weeds. \\n1:07 \\nYou\\'re a writer. You used to be reporter. You\\'ve been a war correspondent. What am I missing? \\n1:12 \\n- I\\'m a professor of journalism at Utah State University. - Right, it\\'s not Harvard University, but it\\'s - - \\nIt\\'s the Harvard University of the Mountain West. \\n1:20 \\n- Anyway, you\\'re brilliant at writing, and I certainly couldn\\'t have written this book without you. \\n1:25 \\nBut this podcast... We talk a lot every week. - Yeah. - We\\'re writing another book, \\n1:31 \\nwhich will be due out, we hope, probably next year? - Oh dear God.[laughs] - Yeah, well.. \\n1:36\\n</context>\\nHuman: Please write me a summary of the text, and I\\'ll read it back to you.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_output(user_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a54859ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer any use questions based solely on the context below:\n",
      "\n",
      "<context>\n",
      "ourselves and others, \n",
      "3:20 \n",
      "is that we are at a turning point in medical history. We finally, as a species, \n",
      "3:25 \n",
      "understand how to control our biology, how to optimize our bodies, during early life, mid-life and \n",
      "certainly late life, \n",
      "3:33 \n",
      "to lead lives that can be decades longer and healthier. And we want to share that information. \n",
      "3:38 \n",
      "It's very hard for the average person to understand, let alone digest, thousands of scientific papers. \n",
      "3:45 \n",
      "That's what I do. I have a team of researchers and in fact, today, we're supported by a team of \n",
      "researchers who have helped us gather information\n",
      "\n",
      "of where we were in Lifespan. \n",
      "12:21 \n",
      "There's a lot to talk about, including things that you can apply in your daily lives, that we didn't know \n",
      "when Lifespan was written. \n",
      "12:27 \n",
      "- One of misconceptions I think a lot of people have about the book, a lot of people have about your \n",
      "research, is they think that you're trying to prevent old age? \n",
      "12:36 \n",
      "- Well, we are, but that's not the only thing. - Because what we're talking about, really, is preventing \n",
      "aging, \n",
      "12:41 \n",
      "and that doesn't just happen when we are old. - Of course not. In fact, it happens over your whole entire\n",
      "lifespan, \n",
      "12:48 \n",
      "even before you're born. - We're going to get into exactly how we know that, but this is fascinating. \n",
      "This is a fascinating area of research. \n",
      "12:55 \n",
      "There's been recent studies on this, which can actually measure, in utero, an infant's age. \n",
      "13:01 \n",
      "- Yeah, in fact, when we're young, we're aging faster than when we're old. But we'll talk about that\n",
      "\n",
      "56:20 \n",
      "That's a big deal. This is, I think, a turning point in medical history, that we actually understand \n",
      "56:26 \n",
      "what causes those diseases fundamentally, not just trying to fix the actual problem when it occurs. \n",
      "56:32 \n",
      "I liken this to get getting to the edge of a cliff. And you wrote this in the book, \n",
      "56:38 \n",
      "is that we've been far too often working on trying to understand why we falling off a cliff \n",
      "56:44 \n",
      "at the end of life, without even asking the question, \"What brings us to the edge of that cliff in the first \n",
      "place.\" Now we finally understand how we get to that cliff, \n",
      "56:51 \n",
      "and even how to prevent it. - And so at some point perhaps we don't have to worry about diseases \n",
      "56:59 \n",
      "because we're going to be so healthy. So young that they're not going to push us off. \n",
      "57:06 \n",
      "They're going to make us sick, maybe. We can treat that. But- - Well, as we saw with COVID-19, that if\n",
      "you're young, \n",
      "57:12\n",
      "\n",
      "with the questions that I need to ask myself. And that's what gave rise to Lifespan. \n",
      "2:00 \n",
      "It was asking the questions that I didn't even know I needed to answer. - And for me, that experience is \n",
      "like, \n",
      "2:08 \n",
      "and whenever I work with anybody on a book, but especially, for whatever reason, the way we've hit it \n",
      "off, I feel, \n",
      "2:14 \n",
      "coming away from these conversations, that I've just gone through a graduate course of study. And to \n",
      "think that I don't have any personal expertise, \n",
      "2:20 \n",
      "and I didn't go to school to do what you do, but I come away from these conversations, \n",
      "2:26 \n",
      "and I feel like I've been in class. In a really good way, cause I'm a lifelong learner. \n",
      "2:32 \n",
      "I love this, right? I'm a student right now. And that's something that we can share with everyone. \n",
      "2:40 \n",
      "- Well, it sounds corny, but it really is a match made in heaven. Before I met you, you had written a \n",
      "book about epigenetics. \n",
      "2:46\n",
      "</context>\n",
      "Human: What is the main idea of the text? (The main idea of the text is that humans are aging faster than they used to be. We\n"
     ]
    }
   ],
   "source": [
    "print_output(\"What is the main idea of the text?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
