{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0f0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71f65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the module using forward slashes\n",
    "module_path = Path(\"../scripts/10_SN_Pub_retrieval.py\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27331ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a module spec from the file location\n",
    "spec = importlib.util.spec_from_file_location(\"module_name\", module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a61bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new module based on the spec\n",
    "module = importlib.util.module_from_spec(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a30ecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved date: 2025-04-01\n"
     ]
    }
   ],
   "source": [
    "# Execute the module\n",
    "spec.loader.exec_module(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98799e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the desired function\n",
    "fetch_papers_from_SpringerNature = module.fetch_papers_from_SpringerNature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ba26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers from SpringerNature...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fetch_papers_from_SpringerNature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74240a8e",
   "metadata": {},
   "source": [
    "Here's a Python script that fetches up to 500 documents related to \"longevity\" from the Springer Nature Metadata API and stores them locally. This script adheres to Springer Nature's API usage policies to ensure compliance and avoid potential blacklisting.\n",
    "\n",
    "ðŸ”§ Prerequisites\n",
    "API Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../.env', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Hugging Face token from environment variables\n",
    "sn_api_key = os.getenv('SPRINGERNATURE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a06e0",
   "metadata": {},
   "source": [
    "Query String Parameters\n",
    "This section introduces key fields such as 'q' for the query, 's' for the starting result, and p for the number of results per page. The following query string parameters can be passed to the API to customize how the results are displayed:\n",
    "\n",
    "|Parameter|Description|Required|Default Value|\n",
    "|---|---|---|---|\n",
    "|q|The query to be performed by the API. Supports various filters.|yes||\t\n",
    "|s|Return results starting at the number specified.|no|1|\n",
    "|p|Number of results to return in the request. (See section Pagination and Limits for more details.)|no|10|\n",
    "|api_key|The key identifying your application.|yes||\n",
    "\t\n",
    "If the p parameter is not included, 10 results will be returned by default. If the s parameter is omitted, the results will start from the first entry. The q parameter offers flexible options, allowing you to build complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # 43587 is the Nature Aging\n",
    "        #'journalid' : 43587 ,\n",
    "        #'p': PAGE_SIZE,\n",
    "        #'s': start,\n",
    "        #'datefrom': '2024-01-01',\n",
    "        #'dateto': '2025-04-23'\n",
    "        #'pub' : 'Nature Aging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual API key\n",
    "API_KEY = sn_api_key\n",
    "QUERY = \"journalid:43587 AND onlinedatefrom: 2024-01-01\"\n",
    "MAX_RESULTS = 400\n",
    "PAGE_SIZE = 10  # Maximum allowed by the API is 100\n",
    "OUTPUT_DIR = '../data/springer_longevity_docs'\n",
    "API_ENDPOINT = 'https://api.springernature.com/openaccess/json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e18383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1116de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_documents():\n",
    "    total_fetched = 0\n",
    "    start = 30  # Springer API uses 1-based indexing\n",
    "\n",
    "     #'q': f'{QUERY} sort:date',\n",
    "    while total_fetched < MAX_RESULTS:\n",
    "        params = {\n",
    "        #'query': \"Keyword:lifespan\",\n",
    "        'api_key': API_KEY,\n",
    "        'q' : QUERY,\n",
    "        's' : start\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(API_ENDPOINT, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            records = data.get('records', [])\n",
    "            print(\"params: \", params)\n",
    "            if not records:\n",
    "                print(\"No more records found.\")\n",
    "                break\n",
    "\n",
    "            for record in records:\n",
    "                if record:\n",
    "                    # Pretty-print the JSON record to the console\n",
    "                    print(json.dumps(record, indent=2))\n",
    "\n",
    "                    doc_id = record.get('identifier', f'doc_{start}')\n",
    "\n",
    "                    filename = OUTPUT_DIR + \"/\" + f\"{doc_id.replace(':', '_').replace('/', '_')}.json\"\n",
    "                    \n",
    "                    print(\"record.geturl: \")\n",
    "                    print (record.get('url'))\n",
    "\n",
    "                    with open(filename, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(record, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "                    # Attempt to retrieve full-text URL\n",
    "                    full_text_url = None\n",
    "                    for link in record.get('url', []):\n",
    "                        if link.get('format') == '':\n",
    "                            full_text_url = link.get('value')\n",
    "                            print(\"fulltexturl:\" + full_text_url)\n",
    "                            break\n",
    "\n",
    "                    if full_text_url:\n",
    "                        try:\n",
    "                            full_text_response = requests.get(full_text_url, timeout=10)\n",
    "                            full_text_response.raise_for_status()\n",
    "                            full_text_content = full_text_response.text\n",
    "                            full_text_filename = OUTPUT_DIR + \"/\" + f\"{doc_id.replace(':', '_').replace('/', '_')}_fulltext.xml\"\n",
    "                            print(\"Full text filename: \"+full_text_filename)\n",
    "                            #full_text_filename = os.path.join(OUTPUT_DIR, f\"{safe_doc_id}_fulltext.xml\")\n",
    "                            with open(full_text_filename, 'w', encoding='utf-8') as ft_file:\n",
    "                                ft_file.write(full_text_content)\n",
    "                        except requests.exceptions.RequestException as e:\n",
    "                            print(f\"Failed to retrieve full text for {doc_id}: {e}\")        \n",
    "\n",
    "            fetched_count = len(records)\n",
    "            total_fetched += fetched_count\n",
    "            print(f\"Fetched {fetched_count} records. Total fetched: {total_fetched}\")\n",
    "\n",
    "            if fetched_count < PAGE_SIZE:\n",
    "                # Fewer records than page size indicates no more data\n",
    "                break\n",
    "\n",
    "            start += PAGE_SIZE\n",
    "\n",
    "            # Respectful delay between requests\n",
    "            time.sleep(1)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "\n",
    "# Get today's date in ISO 8601 format (YYYY-MM-DD)\n",
    "today = date.today().isoformat()\n",
    "\n",
    "# Create a dictionary with the date\n",
    "data = {'date': today}\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('../data/SpringerNature_last_retrieval_date.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(\"Today's date has been saved to 'SpringerNature_last_retrieval_date.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ee0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open('../data/SpringerNature_last_retrieval_date.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the date value\n",
    "date_string = data.get('date')\n",
    "\n",
    "print(f\"Retrieved date: {date_string}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
